{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03872472-f35d-4dd2-90ba-dd63208d60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from google.cloud import storage\n",
    "import io\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "from matplotlib import pylab as P\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6f84c-c4a9-4266-8121-368718a9a609",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172b15a-478c-4336-9c16-989b29e01492",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('dl-cnn-data')\n",
    "\n",
    "categories = ['flower', 'apple', 'baseball', 'basketball', 'bird', 'book', 'bus', 'car', 'cat', 'dog']\n",
    "label_dict = {0:'flower', 1:'apple', 2:'baseball', 3:'basketball', 4:'bird',\n",
    "                      5:'book',6:'bus', 7:'car', 8:'cat', 9:'dog'}\n",
    "# Data Hyperparameters\n",
    "test_set_split = 0.2\n",
    "max_items_per_class = 10000\n",
    "verbose = True\n",
    "IMAGE_SIZE = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcb39f-0aa0-4268-8006-86db0646beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_write = False\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for idx, category in label_dict.items():\n",
    "    if verbose:\n",
    "        print (idx, category)\n",
    "        \n",
    "    blob = bucket.get_blob('raw_data/' + category + '.npy')\n",
    "    with io.BytesIO() as in_memory_file:\n",
    "        blob.download_to_file(in_memory_file)\n",
    "        in_memory_file.seek(0)\n",
    "        category_data = np.load(in_memory_file)\n",
    "        \n",
    "    category_data = category_data[0:max_items_per_class, :]\n",
    "    category_data = pd.DataFrame(category_data)\n",
    "    category_data['label'] = idx\n",
    "    \n",
    "    data = pd.concat([data, category_data], axis=0, ignore_index=True)\n",
    "\n",
    "data = data.loc[np.random.permutation(data.shape[0]), :]\n",
    "\n",
    "if is_write:\n",
    "    data.to_csv('cnn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d649d50-2e6e-4fda-8914-80be3e4c6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:, 0:-1], data.iloc[:, -1], \n",
    "    test_size=test_set_split, random_state=0)\n",
    "\n",
    "X_train = torch.from_numpy(np.array(X_train)).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).long()\n",
    "y_test = torch.from_numpy(np.array(y_test)).long()\n",
    "\n",
    "def _preprocess_X(input_data):\n",
    "    input_data = input_data.reshape(input_data.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    input_data = input_data.permute((0, 3, 1, 2))\n",
    "    output = input_data / 255.\n",
    "    return output\n",
    "\n",
    "X_train = _preprocess_X(X_train)\n",
    "X_test = _preprocess_X(X_test)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_train, y_train = X_train.cuda(), y_train.cuda() \n",
    "    X_test, y_test = X_test.cuda(), y_test.cuda() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9a38f-a875-410d-aa06-afd301108776",
   "metadata": {},
   "source": [
    "# CNN and Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103c59a-f712-4a08-937b-add7c5e416b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 10\n",
    "\n",
    "dropout = 0.0\n",
    "weight_decay = 0.0\n",
    "# n_chunks = 700\n",
    "# learning_rate = 0.001\n",
    "optimizer = 'SGD'\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13960b51-6de4-4883-b5b8-badcb5999771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, epochs = 10, n_chunks = 1000, learning_rate = 0.003, \n",
    "          weight_decay = 0, optimizer = 'SGD', is_time=False):\n",
    "    \n",
    "    print(\"Training model with epochs = {epochs}, learning rate = {lr}\\n\".format(epochs = epochs, lr = learning_rate))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer ==  'ADAM':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        print (\"ERROR: optimizer undefined\")\n",
    "    \n",
    "    losses = []\n",
    "    res_train = []\n",
    "    res_test = []\n",
    "    res_time = []\n",
    "    for epoch in range(epochs):\n",
    "        print (epoch)\n",
    "        \n",
    "        if is_time:\n",
    "            start_time = time.time()\n",
    "        \n",
    "        running_loss = 0\n",
    "        images = torch.chunk(X_train, n_chunks)\n",
    "        labels = torch.chunk(y_train, n_chunks)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            if (i%500 == 0):\n",
    "                print (\"processing \", i)\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(images[i])\n",
    "            loss = criterion(output, labels[i].squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        losses.append(running_loss)\n",
    "        print(\"Epoch: {}/{}... \".format(epoch + 1, epochs), \"Loss: {:.4f}\".format(running_loss))\n",
    "        \n",
    "        accuracy_train, accuracy_test = evaluate_model(model, X_train, y_train, X_test, y_test, n_samples_tested=10000000000)\n",
    "        res_train.append(accuracy_train)\n",
    "        res_test.append(accuracy_test)\n",
    "        print (\"accuracy\", accuracy_train, accuracy_test)\n",
    "        \n",
    "        if is_time:\n",
    "            time_taken = time.time() - start_time\n",
    "            res_time.append(time_taken)\n",
    "            print ('time taken', time_taken)\n",
    "            \n",
    "        res = losses, res_train, res_test\n",
    "        if is_time:\n",
    "            res = losses, res_train, res_test, res_time\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_prediction_probability_distribution(model, input_data):\n",
    "    with torch.no_grad():\n",
    "        logits = model.forward(input_data)\n",
    "    return torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "def get_labels(model, input_data):\n",
    "    probability_distribution = get_prediction_probability_distribution(model, input_data)\n",
    "    pred_labels = torch.argmax(probability_distribution, axis=1, keepdims=True)\n",
    "    return pred_labels\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, n_samples_tested = 5000):\n",
    "    train_pred_labels = get_labels(model, X_train[:n_samples_tested])\n",
    "    test_pred_labels = get_labels(model, X_test[:n_samples_tested])\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train[:n_samples_tested].cpu(), train_pred_labels.cpu())\n",
    "    accuracy_test = accuracy_score(y_test[:n_samples_tested].cpu(), test_pred_labels.cpu())\n",
    "\n",
    "    print(\"Accuracy score for train set is {} \\n\".format(accuracy_train))\n",
    "    print(\"Accuracy score for test set is {} \\n\".format(accuracy_test))\n",
    "\n",
    "    return accuracy_train, accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924bdef-e042-46b1-b5c5-7d9c071b85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key_to_name = {\n",
    "    0: 'cnn',\n",
    "    1:'resnet18',\n",
    "    1.5: 'resnet18_eval',\n",
    "    2:'resnet34',\n",
    "    3:'resnet50',\n",
    "    4:'alexnet',\n",
    "    5:'vgg16',\n",
    "    6:'custom_resnet18',\n",
    "}\n",
    "model_key = 1\n",
    "\n",
    "learning_rate_list = [0.05]\n",
    "\n",
    "n_chunks_list = [2000]\n",
    "\n",
    "kernel_sizes = [3, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2096a2-404a-40ed-a478-374eaf402c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18 = models.resnet18(pretrained=False)\n",
    "# resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=k, stride=1, padding=1,bias=False)\n",
    "# resnet18.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "# model = resnet18\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5b8d3-9216-40ea-9999-968157777f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ebfae-519c-4283-abbf-a676f40664a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rate_list:\n",
    "    for cur_chunks in n_chunks_list:\n",
    "    # for k in kernel_sizes:\n",
    "        # try:\n",
    "        if model_key == 0:\n",
    "            model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('maxpool1', nn.MaxPool2d(2, stride=None)),\n",
    "    \n",
    "          ('conv3', nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)),\n",
    "          ('relu3', nn.ReLU()),\n",
    "          ('conv4', nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)),\n",
    "          ('relu4', nn.ReLU()),\n",
    "          ('maxpool2', nn.MaxPool2d(2, stride=None)),\n",
    "    \n",
    "          ('conv5', nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=0)),\n",
    "          ('relu5', nn.ReLU()),\n",
    "          ('conv6', nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=0)),\n",
    "          ('relu6', nn.ReLU()),\n",
    "          ('maxpool2', nn.MaxPool2d(2, stride=None)),\n",
    "    \n",
    "          ('dropout', nn.Dropout(0.1)),\n",
    "          ('flatten', nn.Flatten()),\n",
    "          ('fc1', nn.Linear(256, output_size)),\n",
    "          # ('tanh', nn.Tanh()),\n",
    "          # ('fc2', nn.Linear(512, output_size)),\n",
    "          # ('relu7', nn.ReLU()), \n",
    "        ]))\n",
    "        elif model_key == 1:\n",
    "            resnet18 = models.resnet18(pretrained=False)\n",
    "            resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "            resnet18.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "            model = resnet18\n",
    "        elif model_key == 1.5:\n",
    "            resnet18 = models.resnet18(pretrained=False)\n",
    "            resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "            resnet18.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "            model = resnet18\n",
    "            model.eval()\n",
    "        elif model_key == 2:\n",
    "            resnet34 = models.resnet34(pretrained=False)\n",
    "            resnet34.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "            resnet34.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "            model = resnet34\n",
    "        elif model_key == 3:\n",
    "            resnet50 = models.resnet50(pretrained=False)\n",
    "            resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "            resnet50.fc = nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "            model = resnet50\n",
    "        elif model_key == 4:\n",
    "            alexnet = models.alexnet(pretrained=False)\n",
    "            alexnet.features[0] = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)\n",
    "            # changed for kernel size and stride, else 0 dimension\n",
    "            alexnet.classifier[6] = nn.Linear(in_features=4096, out_features=10, bias=True)\n",
    "            model = alexnet            \n",
    "        elif model_key == 5:           \n",
    "            vgg16 = models.vgg16(pretrained=False)\n",
    "            vgg16.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "            for l in vgg11.features:\n",
    "                if type(l) == torch.nn.modules.conv.Conv2d:\n",
    "                    l.kernel_size = (2, 2)\n",
    "            vgg16.avgpool: nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
    "            vgg16.classifier[0] = nn.Linear(in_features=12544, out_features=4096, bias=True)\n",
    "            vgg16.classifier[6] = nn.Linear(in_features=4096, out_features=10, bias=True)\n",
    "            vgg16.features = vgg16.features[:11]\n",
    "            model = vgg16\n",
    "        elif model_key == 6:\n",
    "            resnet18 = models.resnet18(pretrained=False)\n",
    "            resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=1,bias=False)\n",
    "            resnet18.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "            model = resnet18\n",
    "        else:\n",
    "            print (\"model undefined\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "        \n",
    "        losses, res_train, res_test= train(model, X_train, y_train,\n",
    "                                    epochs=epochs,\n",
    "                                    learning_rate = lr, \n",
    "                                    weight_decay = weight_decay,\n",
    "                                    n_chunks = cur_chunks,\n",
    "                                    optimizer=\"SGD\")        \n",
    "        # losses, res_train, res_test, res_time = train(model, X_train, y_train,\n",
    "        #                             epochs=epochs,\n",
    "        #                             learning_rate = lr, \n",
    "        #                             weight_decay = weight_decay,\n",
    "        #                             n_chunks = cur_chunks,\n",
    "        #                             optimizer=\"SGD\", \n",
    "        #                                    is_time=True)\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        res['TrainLoss'] = losses\n",
    "        res['TrainAccuracy'] = res_train\n",
    "        res['TestAccuracy'] = res_test\n",
    "        # res['Time'] = res_time\n",
    "\n",
    "        file_name = model_key_to_name[model_key] + '_' + str(lr) + '_' + str(cur_chunks)\n",
    "        res.to_csv('results/' + file_name + '_20epochs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffc372-f0da-4ca1-b502-70ee345a38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_save = False\n",
    "if is_save:\n",
    "    torch.save(resnet18.state_dict(), 'results/resnet18_0.1_2000.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742fc48-8015-4581-bf1d-f174db5e1f99",
   "metadata": {},
   "source": [
    "# Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654059e3-52e1-4833-92df-6a114fe2cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Wrap the input tensors in Variables\n",
    "    X_var = Variable(X, requires_grad=True)\n",
    "    y_var = Variable(y)\n",
    "    saliency = None\n",
    "    \n",
    "    scores = model(X_var)\n",
    "    labels_scores = scores.gather(1, y_var.view(-1, 1)).squeeze()\n",
    "    \n",
    "    loss = -torch.sum(torch.log(labels_scores))\n",
    "    loss.backward()\n",
    "    \n",
    "    images_grads = X_var.grad.data\n",
    "    abs_images_grads = images_grads.abs()\n",
    "    saliency, _ = abs_images_grads.max(dim=1)\n",
    "\n",
    "    return saliency\n",
    "\n",
    "\n",
    "def show_saliency_maps(X, y, path=None, vmax=0.3):\n",
    "    # Convert X and y from numpy arrays to Torch Tensors\n",
    "    X_tensor = X#torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n",
    "    y_tensor = y\n",
    "\n",
    "    # Compute saliency maps for images in X\n",
    "    saliency = compute_saliency_maps(X_tensor, y_tensor, resnet18)\n",
    "\n",
    "    # Convert the saliency map from Torch Tensor to numpy array and show images\n",
    "    # and saliency maps together.\n",
    "    saliency = saliency.cpu().numpy()\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        plt.imshow(X[i][0].cpu())\n",
    "        # plt.axis('off')\n",
    "        # plt.title('Saliency Map')\n",
    "        plt.subplot(2, N, N + i + 1)\n",
    "        plt.imshow(saliency[i], cmap=plt.cm.hot, vmin=0, vmax=vmax)\n",
    "        plt.savefig(path)\n",
    "        # plt.axis('off')\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "    plt.show()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81233de1-566a-4944-94f6-4a57142991f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in y_test[[1, 6, 4, 11]]:\n",
    "#     print (categories[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54acb1-a31c-4a8f-ac72-4d26863faf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = show_saliency_maps(X_test[[1, 6, 4, 11]], y_test[[1, 6, 4, 11]], path='results/resnet18_saliency_correct.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798f522-3636-46bf-9d0a-1bb32f9b386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = get_labels(resnet18, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd5080a-c3d9-45c2-a2eb-3a7185b80bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassify_res = pd.DataFrame(columns=['index', 'pred', 'actual'])\n",
    "for i in range(len(test_pred_labels)):\n",
    "    if test_pred_labels[i][0] != y_test[i]:\n",
    "        misclassify_res = misclassify_res.append(\n",
    "            {'index': i,\n",
    "             'pred': categories[test_pred_labels[i][0]],\n",
    "             'actual': categories[y_test[i]] }, \n",
    "            ignore_index=True)\n",
    "print (misclassify_res.head(10))\n",
    "misclassify_res.to_csv('results/misclassify.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a5b9a-28c6-4781-95c6-36d91678bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_saliency_maps(X_test[[5, 16, 38, 69]], y_test[[5, 16, 38, 69]], path='results/resnet18_saliency_incorrect.png')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
